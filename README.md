# RunLengthCompression

    Runlength encoding is a form of lossless compression that records “runs”, which are sequences of data that have the same value. I chose to write a run-length encoder from scratch because I believed it to be a decent form of compression for animated clips. I hypothesized that it would work especially well with the animated bunny clips vs the other movie clips because animators tend to only animate what needs to be animated. Backgrounds tend to have little movement or be completely static, which would provide lots of runs for us to compress.
    
    One of the risks of run-length encoding is that it can actually increase file size if there aren’t enough runs. Before I started this assignment, I made sure it would perform at somewhat decently on the bunny.yuv file by changing the boilerplate huffman encoder from class to record the pairs of unchanging pixels from frame to frame. To clarify, frame by frame means examining pairs along frames. For example, a pair would be the pixels at (0,0,0) and (0,0,1). Pairing along the z axis makes most sense considering the animation style of the clip. If backgrounds are relatively nonmoving or static, their values will not change much as the video goes on, meaning longer runs. In the bunny.450p.yuv file, out of 800 x 450 x 149 = 53640000 pairs, 33640550 pairs were equal value from frame to frame, or 62.72%.
    
    Before we start analyzing this data, we must first discuss the method of implementing run-length encoding. One naive approach that I immediately discarded was looking for pairs along the xy plane. In other words, we would directly read bytes and compare them to adjacent bytes in the .yuv file. However, this is not optimal because then we take advantage of the static backgrounds of animation that was discussed earlier. Instead, we would read the values into a 3d array (an arraylist of 2d arrays), then loop along the z axis to search for runs. This method does introduce some inefficiency in compressing/decompressing time because we have to read in all the bytes before starting encoding/decoding, but it should give us better compression results than if we looped along the xy plane. Typically, people care more about compression rate rather than compression time, as long as it’s not exorbitant.
    
    The first method that I went with was rather simple, and is called “runLength” in the github code. It encodes every run as 2 bytes; one for the length of the run, and one for the value of the pixel. I had to use an entire byte for the length of the run because we had 150 frames. This way, runs of length 1 would double in space, runs of length 2 would stay the same, and runs of length n>2 would save n-2 bytes of space.
    
    Now to analyze the data from before. We know that after running the compression, we expect the file size to decrease. Since we have more matching pairs than nonmatching, we know that we will definitely have runs that are greater than length 2, which means we start saving space, and for every byte that’s doubled from length 1 runs, we’ll save a byte from a matching run. This was confirmed, as the 52,735 KB bunny.450p.yuv file was compressed to 39,765 KB, which is a 25.6% reduction in size.
    
    Another idea I came up with was using one “information byte” to determine the “run status” of the next 8 bytes. A 0 would indicate a pixel not in a run, which would only take 1 byte to encode. A 1 would indicate a run, which takes 2 pixels. This way, we no longer double the space needed to encode bytes not in a run and keep the cost of 2 bytes per run. The information byte is necessary because without it, we don’t know if single pixels not in a run are single pixels, or if they are the byte telling us how long the next run is. However, this introduces an overhead of n/8 information bytes. This method would only be more efficient than the first method if more than n/8 of the bytes in the input file were bytes not in a run. In the interest of time, I did not write this code, though it could be an interesting inquiry to follow in the future.
    
    The third method, which I called “SplitRunLength” and can be found in the github repository, records “matching runs”, which are the runs I have been describing, as well as “nonmatching runs”. Nonmatching runs are runs where the the pixels don’t match. The theory behind this method is that in animation, moving parts of the screen tend to stay moving, and static parts tend to stay static. For example, scenery typically stays static or only changes slightly, while characters like the bunny are dynamic and are constantly changing, which would be great for nonmatching runs. I called this “SplitRunLength” because instead of using an entire byte to encode the length of a matching run, 0-127 would encode a nonmatching run of length 1-128, and 128-255 would encode matching runs of length 2-129 (since matching runs are minimum length 2). This method does not come without inefficiencies, however. Since we have 150 frames and max runLength of 128 or 129, the longest runs might be split. However, longer runs are more unlikely to occur, so I didn’t expect many runs to be split. Another inefficiency comes in encoding time. Matching runs are easy to encode because once we know the value of it, we can go ahead and write that value to the output file, count the length, then write the runLength. For nonmatching runs, however, we must first count how long the nonmatching run is, then write the run-length before we can start writing each value in the nonmatching run, which is an extra for loop in the code. This method was quite challenging to code, since there were a plethora of off-by-one factors to account for, but it was worth it! SplitRunLength encoding compressed the 52,735 KB bunny.450p.yuv file to 32,834 KB, which is a 38.7% decrease in size, an additional 13.1% knocked off from the first method!
    
    When I ran my compression program on the candle.450p.yuv file, the results were outstanding. The first method reduced file size by 96.4%, the second by 95.5%. This is because most of the video is just a black background, which ends up containing huge runs. The second method was actually worse because there were so many matching runs of length >129. Unfortunately, it still did not beat the arithmetic encoder, because it was also able to take advantage of the huge number of black pixels.
    
    In conclusion, runlength encoding worked decently for the animated bunny .yuv file and incredibly well for the candle file. It generally did not perform as well as the arithmetic encoder from class because the runs in all the files were not long enough to beat arithmetic encoding. I believe this was because of the complexity of the video files we were given. They were realistic or almost realistic, leading to shorter runs and a multitude of pixels that weren’t in a run at all. Simpler or older animations with fewer color changes and more static backgrounds or monobackground movies like the candle clip would would be better served under runlength compression. However, since people generally need something that will compress all videos well and not just specific types of videos, runlength encoding by itself probably doesn’t have much space in modern compression techniques.
